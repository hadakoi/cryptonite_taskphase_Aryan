# Where are the robots

## Method

In this challenge we are promted to find the robots.
Upon opening a website we can see it asking "Where are the robots?"

From here we can understand that we need to enter the robots.txt.

It is  a simple text file used by websites to communicate with web crawlers and search engine bots. It tells bots which parts of the site they are allowed or disallowed to access.

We can enter it by type /robots.txt at the end of the url. 

Entering this url we see 2 text lines

```
User-agent: *
Disallow: /1bb4c.html
```
A User-agent is a string that web browsers, bots, and other clients send to a web server as part of the HTTP request header. 

In this case using * makes sure that  all bots are not allowed. 

Disallow: /1bb4c.html . This directive instructs bots not to access or crawl the specific page located at /1bb4c.html doesent mean we cannot do it :D

So at the end of the url removing /robots.txt we add /1bb4c.html

Upon entering the website we see that we have now found the robots and the flag.


## Flag

> picoCTF{ca1cu1at1ng_Mach1n3s_1bb4c}

![image](https://github.com/user-attachments/assets/fa3562e4-8c4e-4e41-b1af-0397e3f5f401)
![image](https://github.com/user-attachments/assets/56035055-75b4-42eb-a17e-f92ccde2d8eb)
