# Where are the robots

## Method

In this challenge we are promted to find the robots.
Upon opening a website we can see it asking "Where are the robots?"

From here we can understand that we need to enter the ``robots.txt``.

It is  a simple text file used by websites to communicate with web crawlers and search engine bots. It tells bots which parts of the site they are allowed or disallowed to access.

We can enter it by type ``/robots.txt`` at the end of the url. 

Entering this url we see 2 lines of text

```
User-agent: *
Disallow: /1bb4c.html
```

User-agent: * specifies that the rule applies to all bots. * basically refers to all.

Disallow: /1bb4c.html instructs bots not to access or crawl the page located at /1bb4c.html. Luckily this does not prevent us from visiting the page directly.

So we can just add ``/1bb4c.html`` to the url end.

Upon entering the website we see that we have now found the robots and the flag.


## Flag

> picoCTF{ca1cu1at1ng_Mach1n3s_1bb4c}

![image](https://github.com/user-attachments/assets/fa3562e4-8c4e-4e41-b1af-0397e3f5f401)
![image](https://github.com/user-attachments/assets/56035055-75b4-42eb-a17e-f92ccde2d8eb)
